\documentclass{article}

\usepackage{ wasysym }
\usepackage{ amssymb }

\begin{document}
\title{Secure Collaborative Editing for the Masses}
\author{Benjamin Ylvisaker}

\maketitle

\section{Introduction}

Collaborative editing applications help teams work and socialize together.
Popular examples include Google Docs, Evernote, Etherpad, Slack and Trello.
In all widely used collaborative editing (CE) applications, central services integrates teammates' edits into a consistent database/document and store that database.
In many cases these services are operated by the developers of the application.

If a team has concerns (even mild ones) about protecting their data from exposure or tampering, relying on these kinds of services is extremely problematic.
The team's data is vulnerable to the service provider's incentives not matching the users', poor operational security, and interference from outsiders like governments and courts.
There is now an extensive literature, both scholarly and popular, on the risks associated with data exposure and manipulation; in this paper we take for granted that many teams are motivated to protect their data from \emph{anyone} outside the team.

In recent years, similar privacy concerns have led to wide adoption of secure messaging protocols and applications like OTR, Signal, WhatsApp and Telegram \cite{}.
CE is similar to messaging, but with two additional challenges:
\begin{enumerate}
\item The data is persistent.
  Edits in CE systems are similar to messages in messaging systems, but basic functionality requires that ``old'' edits be accessible to clients in an efficiently queryable format.
\item Edits from teammates need to be integrated into a consistent document{\slash}database.
  In messaging applications, it is typically not a big problem if users see messages in slightly different orders, or if users ``say'' things that are contradictory in some sense.
  In CE, teammates need to converge towards a coherent view of concurrent (potentially conflicting) edits.
\end{enumerate}

There are a few experimental secure/private CE architectures (e.g. SPORC, TRVE Data, PeerPad), but to the best of our knowledge no applications developed on such platforms have gained a significant user base.
The focus of this project is identifying and mitigating remaining impediments to wide adoption of secure CE technologies.
By way of analogy, we note that secure messaging technologies (e.g. PGP/GPG) existed for many years before the current generation of secure messaging applications, but their use was mostly confined to a small group of people with serious data privacy concerns.
By making secure messaging almost as usable/convenient as less secure systems, the newer generation achieved mass adoption (aided, no doubt, by increasing public concern about data security and privacy).
We are developing a protocol called United We Stand (UWS) to explore whether secure CE can similarly be made as usable as traditional centralized architectures.

\section{Security-Convenience-Cost Trade-offs}

There are trade-offs between security/privacy and convenience/usability.
Clever engineering can sometimes bring benefits in one dimension with little loss in the other, but it is unlikely that it is possible to achieve maximal security and convenience in the same system.
We illustrate where we intend UWS to fall in the security-convenience spectrum with two categories of attacks that we deprioritize relative to convenience/usability.

The first category is \emph{targeted} attacks from highly motivated and technically sophisticated adversaries.
Of course, we prefer having as much protection as we reasonably can from such attacks.
However, where tensions exist between such protection and usability, we prefer usability.

The second category is insider threats.
It is impossible to completely prevent data exfiltration by a malicious teammate.
It is important for teams to have some ability to remove teammates suspected of malicious behavior, but we are not willing to sacrifice usability in the name of protection from teammates.

In addition to these security-convenience trade-offs, economic questions play an important role.
In particular, many conventional CE service providers derive profit from users' data.
Business strategies can be as simple as selling users' data to advertisers, or more technical approaches like building statistical models to improve/personalize other (paid) services.
Secure CE systems generally aim to prevent anyone outside of teams themselves from accessing the team's data (ours certainly does).
This means that we have to think creatively about who pays for the storage, communication and computation resources involved.
Whenever possible, we put these costs on end users.
One important hole in this economic story that we leave for cleverer minds is funding the development and maintenance of application code.
(Once upon a time, users paid for software; could this happen again?)

% This is already a challenge in the messaging context; for example,   (who pays for Signal?)

\section{Design Principles for Usable/Convenient Secure CE}

In this section we argue for a set of features that a CE framework needs in order to compete in convenience with conventional centralized systems.
Existing secure CE projects support some of these features, but to the best of our knowledge, none supports all of them.

\begin{itemize}
\item Mostly offline support.
  That is, the system should still work if a user is never simultaneously online with their teammates.
\item Ability to work when teammates are behind firewalls that block incoming connections.
\item Automatic merging of concurrent edits (not least those made by offline users).
\item Multiple simultaneous ``connections'' from a single user.
\item Available anywhere.
  That is, it should be possible to use the system without first downloading a team's complete database.
\item Low latency.
  See below for what we mean by ``low''.
\item Database size scalability.
\item Team size scalability.
\item Efficient team and team membership management.
\end{itemize}

\subsection{Mostly Offline Support and Firewalls}

Secure CE systems have intrinsic tensions with servers.
Even systems (like SPORC) that only send encrypted data to servers are still more vulnerable to some attacks than purely decentralized systems.
First, surveilance can be more easily carried out on central servers than decentralized communication.
Such surveilance can allow attackers to gain information about teammate identities and communication patterns.
Second, central servers are easier for censors to block than decentralized communication.
In recent years there have been several examples of governments and/or courts blocking secure messaging systems (e.g. WhatsApp in Brazil, Telegram in Russia, Signal in several countries).
Such blocking is feasible because clients need to communicate with central servers for these systems to function.
Third, any server designed in to a protocol raises the question of who pays for the operation of that server.

On the other hand, purely decentralized communication patterns have two critical usability problems relative to conventional CE.
First, users must be online simultaneously to exchange edits.
While this could work for some users in some contexts, it is problematic for users with intermittent internet connections and/or energy-constrained devices.
Second, firewalls that block incoming connections can make decentralized communication impossible.
The STUN/TURN/ICE protocols can help clients make peer-to-peer conncections through firewalls in some cases, but they do not always work and in some cases rely on server support (which is exactly what we are trying to avoid).

We reemphasize that while it is possible for users to work around these difficulties, we are aiming for a usability experience nearly indistinguishable from centralized services.

In UWS we compromise on the server issue by assuming that every user has a passive cloud storage location of some kind.
For many users, this will be an account with commodity services like Dropbox, Google Drive or Microsoft OneDrive.
More technically savvy users with stronger privacy concerns can run their own storage server at home or with a lower profile cloud provider.
To be clear, we are \emph{not} saying that all UWS data resides with some particular cloud storage provider, but rather that each user brings their own cloud storage location.
Users can choose where to store their data completely independently of any other user's choice.

In our protocol design we strive to minimize the API and performance expectations of the storage server in order to maximize the flexibility that users/system designers have with filling that role.
The interface is essentially simple file upload/download.
The only slightly exotic support that is expected is some atomic checking by the server on upload (e.g. the HTTP If-Match header features).
Details of the storage server API and further server-related mitigations are given below.

(Users with yet higher privacy concerns might be able to do their storage as a Tor Onion Service, or similar.
Further investigation required.)

\subsection{Edit Merging}

Good support for concurrent editing while disconnected is necessary to match the usability of popular CE systems.
A system must both automatically merge concurrent edits when feasible and provide for conflict resolution otherwise.

Many recent CE systems have put a lot of focus on automatic merging with some flavor of operational transformations (OT) or conflict-free replicated data types (CRDTs).
These concurrent edit merging frameworks are useful, but do not themselves provide support for identification and resolution of true conflicts.

We prefer to base our protocol's core data model on a Bayou-like totally ordered chain of edits/transactions.
It is conceptually straightforward to build OT or CRDT like data abstractions on top of such a model.
More details below.

\subsection{Single-User Concurrent Access}

It is common for users to have multiple ``connections'' open to cloud applications (e.g. multiple browser tabs on the same computer or simultaneously using a laptop and a mobile device).
In systems with active servers, this kind of concurrency is just a special case of concurrent edits from different users.
However, UWS is built on passive file servers, which we do not expect to automatically resolve potential conflicts between concurrent uploads from the same user on different devices.
Therefore, extra care must be taken to prevent concurrent sessions from a single user clobbering each other's edits.

\subsection{Server-Based Storage}

Users should have reasonable remote access to their documents/database in the sense that they can log in from a new device and have the same usability experience (or nearly so) as from a computer that they use regularly.

An important implication of this principle is that a protocol must support reasonably efficient query from the storage server.
In other words, it is unacceptable to require users to download a team's complete database to a new device before they can start working with it.

\subsection{Latency}

Obviously, the lower the latency that a system can provide, the better.
Our current prototype uses cloud storage upload as the only communication medium, which imposes a fairly high minimum latency for communicating edits to teammates (multiple seconds is common).

\subsubsection{Cloud Storage-P2P Hybrids}

It should be possible to use P2P connections for lower latency when teammates are simultaneously online, but we have not investigated this in any detail yet.
Several other projects have explored P2P CE, so the only question is how hard it is to hybridize these kinds of communication/storage systems with UWS.

\subsubsection{Latency-Tolerant Applications}

Some applications should work fine, even with relatively high latency.
For example, a shared calendar or reservation system.

Don't need to wait for the server.

\subsection{Scalability}

\subsubsection{Storage}

By default every teammate keeps a complete copy of the team's database in their storage location.
So the aggregate storage requirements grow linearly with team size.

It would be relatively easy to reduce this duplication as long as users trust that their teammates will not delete their part of the shared DB.

\subsubsection{Team Size}

Team size scalability is perhaps the most important weakness of UWS in its current incarnation.
The edit ordering protocol uses vector clock timestamps, so edit size scales linearly with team size.
Also by default there is no hierarchical structure to teams, so everyone needs to monitor every other teammate's storage location for updates.

It is likely that these scalability limitations can be improved, but for a minute we want to focus on the merits of small teams.
The per-team overheads in UWS are high enough that it is better for teams that have some real-world persistence.
(For counter-example, not chatting among a collection of people who happen to be going out some evening.)

dunbar number

\subsection{Team Management}

Central servers can make team management more efficient.
In particular, when adding a new teammate, servers can reduce the communication overhead.
For example, the signed prekeys (stored on a central server) in the Signal protocol exist for the single purpose of making it possible to start a new chat with someone and send the first message before the recipient is even aware of the char request.
UWS does not quite match this level of efficiency in team management, but it is close.

\section{Concurrent Edits}

There has been a great deal of research on detecting conflicts between and automatically merging concurrent edits.
The UWS concurrent edit merging algorithm is closely related to the Bayou approach.

\subsection{Bayou}

In Bayou, the data shared between teammates is a linear chain of edits (\emph{Writes} in their jargon).
Of course, the chains at different clients cannot be identical at all times.
The Bayou system divides the chain into two sections: tentative and committed.
New edits are initially considered tentative.
A consistency protocol is run to decide when edits can graduate from the tentative section to the stable/committed section.

The order of edits in the stable section has been agreed upon, and cannot be changed by subsequent messages from teammates (unless the protocol is violated).
Edits in the tentative section might be reordered or superseded by as-yet-unseen edits.
Clients are free to show data from tentative edits to users, but subsequent order changes can potentially cause arbitrary changes in application state.


The strength of the Bayou approach is that it gives application programmers flexibility ...

\subsection{Updating Bayou}

UWS refines the Bayou model in a few ways:

\begin{itemize}
\item Dumber servers
\item More shades of gray between tentative and committed
\item More flexible querying of not-yet-stable edits
\end{itemize}

\subsubsection{Dumber Servers}

The Bayou project did not consider security/privacy as an issue at all; they were simply trying to make a good decentralized concurrent editing system.
Therefore, the designers did not consider the potential problems of malicious server operators or network monitors.
As a consequence, they assume servers will play a larger role in merging concurrent edits than we are willing to accept.

consequences?

\subsubsection{How Tentative is Tentative?}

As mentioned above, Bayou splits each client's edit chain into two sections: tentative and committed.
We believe that it is useful to consider more intermediate degrees of ``committedness''.
Exactly which levels of committedness are useful will require experimentation with real applications, but UWS currently supports the following levels:

\begin{itemize}
\item Not yet uploaded
\item Uploaded, but not confirmed by the server
\item Upload confirmed, but no acknowledgments from teammates seen
\item Acknowledged by a minority of teammates
\item Acknowledged by a majority of teammates (i.e. committed)
\end{itemize}

We believe acknowledged by a minority of teammates is an especially interesting intermediate state in the following scenario.
Consider a relatively large team, where many teammates log in to the team relatively infrequently.
(Perhaps a good example might be scheduling for volunteer docents at a museum.)
Conventional distributed consensus algorithms demand a majority in order to consider some data committed, because of the possibility that two minority subset of users are isolated from each other.
While this kind of failure is (of course) possible in UWS, we expect it to be extremely rare.
So an application might prefer to display data as committed, even if it has only been acknowledged by a minority of teammates.
(Of course, such an application would need a backup UI/UX in the extremely unlikely event that such data needs to be uncommitted.)

Datomic querying below

\section{Storage}

Network server with the following characteristics:

\begin{itemize}
\item A single user can authenticate in some way and has complete control over their location
\item Upload and download arbitrary byte vectors to/from a path
\item A way to atomically upload and check that no file exists at the upload path
\item A way to atomically upload and check that the currently stored version matches the last version seen by the uploader
\item [optional] Wall-clock timestamps on files
\end{itemize}

We remind the reader that it's simple for a reason

\subsection{Sharing}

As noted above, a potential problem with basic UWS is that the aggregate storage cost scales linearly with team size (i.e. each teammate stores a complete copy of the team's data).
Because of the immutable accumulation of edits model of UWS, it is relatively easy for teammates to share the storage cost.

This sharing idea relies on teammates trusting each other to not delete their part of the team's shared data.
In other words, if a team is sharing the storage cost, it would be easy for a teammate to do a denial of service attack by removing their data.

\section{Database}

Most of the UWS protocol is agnostic with respect to the format of the edits being accumulated.
The current UWS prototype uses a very flexible design stolen from Datomic

\section{Team Management}

Our goal is to define a total order on edits.
We use the following raw ingredients:

\begin{itemize}
\item Each edit is identified by its author's userid and a unique (per-author) serial number provided by the author.
\item Each edit can name up to one edit per teammate as direct predecessors of that edit.
  Each edit must name at least one direct predecessor.
\item Each edit must have a wall-clock timestamp.
\item Each teammate must broadcast in a reasonably timely manner a vector timestamp that indicates the highest serial number they have seen from each teammate.
\end{itemize}

At any time a user can compute a committed timestamp by calculating the min of all their teammates individual vector timestamps.
Any edit that is less than this committed timestamp is considered committed and its order relative to other edits will never change.

We write $e_1{\rhd}e_2$ if $e_1 \in \mathsf{Pred}(e_2)$.

We write $e_1{\rightsquigarrow}e_n$ if there exists a path $e_1{\rhd}e_2, e_2{\rhd}e_3, \ldots, e_{n-1}{\rhd}e_n$

We say $e_1$ happened before $e_2$ ($e_1{\rightarrow}e_2$) if $(e_1 \in \mathsf{Committed} \land e_2 \not\in \mathsf{Committed}) \lor e_1{\rightsquigarrow}e_2 \lor (e_2{\not\rightsquigarrow}e_1 \land \mathsf{TS}(e_1)<\mathsf{TS}(e_2))$










Consistency

In all collaborative editing systems there is the issue of concurrent edits.
We consider this two mostly independent challenges: conflict handling and edit merging.
When concurrent edits conflict with each other, we want the system to provide a mechanism for recognizing and helping users resolve the conflicts.
When concurrent edits do not conflict, we want the system to automatically merge the edits without further user interaction.

We note briefly that the definition of conflicting vs not conflicting should be at the application level, not the system level.
System-level definitions of conflicts (e.g. modifying the same database location) can be simultaneously too rigid and too loose.
As an example of being too rigid, in some application states the users might not care which user's write wins.
On the other hand, a single edit might modify multiple database locations and a conflict rule that focused on individual locations might miss an application-level conflict.
We suggest that collaborative editing systems should focus on providing flexible interfaces to applications for conflict detection and handling.

There has been a great deal of research and implementation work on concurrent edit merging, especially around the ideas of operational transforms (OT) and conflict-free replicated data types (CRDT).
These technologies are important, but they do not help in contexts where there are true conflicts and the order of edits is significant from a usability perspective.
For example, consider a reservation system where it is possible for Alice's reservation to be overridden by Bob's because of a quirk in the consistency protocol, even when Alice's reservation was unambiguously made before Bob's.
We believe that these kinds of situations are common enough that in addition to merging concurrent edits when possible, CE frameworks should establish as accurate an ordering of edits as is practically possible.

Centralized systems can trivially order edits by the order in which they arrive at the central service.
A user might get unlucky and find that their edits are slow to arrive at the central service, but that's life on the internet.
Establishing order in the decentralized context is much harder, as evidenced by the vast amount of research devoted to the topic over decades.

Before explaining the ordering protocol that we use in UWS, we argue against some simpler alternatives.

Perhaps the simplest way to establish order would be to have clients put wall-clock timestamps in every edit that they broadcast.
We mostly trust clients to not be malicious in UWS, so we cannot immediately reject this idea on security grounds.
However, wall-clock timestamps are known to be quite problematic for at least two reasons:
First, a client's clock could be misconfigured, leading to edits that seems to have appeared arbitrarily earlier or later than they actually did.
This problem would almost certainly be even worse in the context of potentially poorly managed end-user computers than, for example, data centers, where timestamp based protocols are sometimes used.
Second, an edit could take a long time to make its way from a client to that user's file server.
Our general system assumption for UWS is that the client computers are much more likely to be flaky or have poor internet connections, whereas we assume the file servers are generally more reliable and performant.
For these reasons we reject using wall-clock timestamps from client computers in any way.

The next source of ordering data we consider is wall-clock timestamps from the file servers.
This is a trickier source of data.
We do not completely trust the file servers, and if these timestamps were used naively, it would be easy for a malicious file server to cause confusion by timestamping files inaccurately or even responding with different timestamps to requests for the same file.
As described below, UWS \emph{does} use timestamps from the file servers, but we believe that it is important to have additional mechanisms to limit the damage that a misbehaving server can do.

In UWS we limit the reliance on server timestamps with an implementation of the classical causal partial order.
The simplest way to eastablish an accurate causal order is to send a vector clock timestamp with every edit.
Unfortunately this strategy severely limits team size scalability, as the amount of metadata sent with \emph{every} edit scales with team size.
We use a common trick that has the same worst-case scaling as vector clocks, but performs much better in the (common) case where the typical time between concurrent edits is relatively long compared to the typical communication latency.

Each client is responsible for maintaining its own set of most recent edits.
Newly uploaded edits include this set of most recent edits as the new edit's direct predecessors.
These direct predecessor sets can be seen as a compressed version of a vector clock, where entries that are implied by chains of predecessors from those named in the edit can be ommitted.

These direct predecessor sets in edits define a causality DAG.
If there is a path from one edit to another in this DAG, then those edits must be processed in that order.
If there is no path from one edit to another, those edits are concurrent and they are ordered by file server timestamp.

\end{document}
