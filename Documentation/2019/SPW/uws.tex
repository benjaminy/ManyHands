%
% 
%

\documentclass[runningheads]{llncs}

\usepackage{ wasysym }
\usepackage{ amssymb }

\begin{document}


\title{Cheap 'n Easy Cloud Storage: The Final Ingredient for Mainstream Secure Collaborative Editing?}
\titlerunning{Cloud Storage for Secure Collaborative Editing}

% \author{Benjamin Ylvisaker\inst{1}\orcidID{0000-0002-8608-7404} \and
% Beau Carlborg\inst{1}\orcidID{}}
\author{Benjamin Ylvisaker\orcidID{0000-0002-8608-7404} \and
Beau Carlborg}
\authorrunning{B. Ylvisaker and B. Carlborg}

\institute{Colorado College, Colorado Springs, CO 80905, USA
  \email{bylvisaker@coloradocollege.edu}}

\maketitle

\begin{abstract}

Collaborative editing applications like Google Docs have had a huge impact on how teams work and socialize together.
Unfortunately, all such applications in wide use today rely on a central service provider to process and store the data.
This is a huge privacy risk.

In recent years secure messaging apps, like WhatsApp and Signal, have become mainstream, suggesting that the public at large has some appetite for privacy-protecting technologies.
A few research groups have observed that secure collaborative editing is achievable (very roughly speaking) by combining secure messaging with a distributed merging{\slash}consensus protocol.

Unfortunately, these secure collaborative editing prototypes have not made it into the mainstream.
In this paper we analyze the reasons for the non-use of this technology and propose adaptations of existing secure messaging and distributed consensus protocols that we believe can make secure collaborative editing a viable replacement for the current centralized architecture.

\keywords{Secure group messaging  \and Collaborative editing \and Cloud storage.}
\end{abstract}

\section{Introduction}

\textbf{A mystery}:
As of early 2019, both \emph{secure} messaging and \emph{trust-the-service-provider} collaborative editing are widely used, \emph{mainstream} technologies.
The core technology ingredients for \emph{secure} collaborative editing (CE) have existed for many years.
A few research teams have even developed prototypes for secure CE systems.
Yet, to the best of the authors' knowledge there is approximately zero mainstream use of secure CE systems.

We propose an explanation of this mystery: The \emph{centralized} system architecture that both popular secure messaging and trust-the-service-provider CE applications use has some problematic issues for secure CE.
In particular, the economics are challenging.
Running a CE service is more costly than a messaging service, because of the storage and repeated querying costs.
However, running any privacy-protecting service does not give the service provider the common business opportunity of deriving profit from users' data.
On the other hand, \emph{distributed} architectures for CE have been studied, but conventional distributed systems suffer from serious usability problems, compared to centralized systems.
While many users are interested in security and privacy, most are willing to sacrifice very little in terms of expense and usability for enhanced security.

We explore a hybrid solution to this system architecture dilemma.
We start from a mostly distributed architecutre: Like all end-to-end encrypted (E2EE) systems, the protocol computation is done by clients.
Furthermore, there is no central server for delivering messages or coordinating clients.
Rather, we require that each user supply his or her own cloud storage location which they use as both the primary storage location for their teams' data (that user's copy, to be precise) and as a broadcast medium for sending their own edits to their teammates.

In this paper we analyze the relative strengths and weaknesses of centralized and distributed architectures for mainstream collaborative editing applications.
We then argue that our distributed plus cloud storage architecture mostly keeps the strengths and avoids the weaknesses of the two conventional architecture styles.
Building a CE framework with this architecture is largely a matter of adapting existing protocols for secure group messaging and concurrent edit branch reconvergence.
We identify and explain a handful of tweaks to traditional protocols necessary to get the most out of this nontraditional architecture.

\subsection{Security Non-Goals}

This project is focused on protecting teams from untargeted attacks like dragnet surveillance.
Two categories of attacks that we are \emph{not} focused on are targeted attacks from a technically sophisticated adversary and insider attacks from teammates.
Of course, we aim for as much resistance to these kinds of attacks as is feasible, but not at the expense of usability.

\section{Background and System Architecture}

\subsection{Concurrent Edit Branch Merging}

In any system that involves concurrent editing there exists the possibility of conficts that need to be resolved in some way.
A wide reange of strategies for this conflicting branch resolution problem exist in different systems.
To mention just a few: in version control systems like git, decisions about branching and merging are substantially manual with some automatic merging support for simple cases; in productivity apps like Office 365 and Google Docs a central service serializes edits and provides a backup user interface in case of conflicts; in proof-of-work blockchains like Bitcoin, a decentralized collection of clients vote with their compute cycles on which of the concurrent branches that exist should ``win'' and be considered canonical.

This project aims to support a reasonably wide range of conflict resolution strategies.
One piece of raw data that can be useful 
An important observation we make here is that centralized systems can easily establish a temporal total order on edits.
While such an order in itself is not a complete conflict resolution strategy, it can be a useful ingredient when there exists a true application semantics level conflict between concurrent edits.
Conventional distributed systems can provide a partial order based on causality, but it is hard to order concurrent edits{\slash}messages{\slash}transactions in such systems.

--
RXWSOF

Collaborative editing applications help teams work and socialize together; some popular examples: Google Docs, Evernote, Etherpad, Slack, Trello.
In all widely used collaborative editing (CE) applications, \emph{central services} process and store teammates' edits{\slash}transactions.
In many cases the application developer and service provider are one and the same organization.

This architecture is problematic from a privacy perspective; service providers have complete control over teams' data.
Teams are vulnerable to service provider incentive misalignment, lapses in operational security, and interference from outsiders like governments and courts.
There is an extensive literature, both scholarly and popular, on risks associated with private data exposure and manipulation.
In this paper we assume that in many cases people are motivated to protect their teams' data from \emph{all} outsiders.

Previous research projects (e.g. SPORC\cite{Feldman2010}, TRVE Data\cite{Kleppmann2018}) demonstrated that secure CE is possible.
However, to the best of our knowledge there is approximately zero mainstream adoption of secure CE applications.
In contrast, secure \emph{messaging} protocols and applications like OTR \cite{Borisov2004}, Signal (\texttt{signal.org}, \cite{Cohn-Gordon2018}), WhatsApp, Telegram, and iMessages are now mainstream.
The question addressed in this paper is: Why are both secure \emph{messaging} and \emph{insecure} collaborative editing widely used, while secure collaborative editing is barely used at all?\footnotemark{}

\footnotetext{Secure file sharing is a partial counterexample to this blanket comment about secure CE.
However, file sharing protocols generally make no attempt at fine-grained integration of concurrent edits, an essential feature for many CE applications.}

We believe that a major factor behind this difference is economic.
Popular secure messaging services use end-to-end encryption (E2EE) protocols to protect users from a variety of attacks, but they rely on central servers to forward messages and facilitate peer-to-peer connections.
In addition to important security and privacy concerns related to central servers, there is the critical issue of funding their operation.
Deriving profit from users' private data (arguably the most common business strategy on the web today) is obviously not viable.
Alternative strategies include offering secure messaging to attract and retain an otherwise valuable user base (Facebook, Apple) and a mysterious combination of donations, grants and licensing deals (Open Whisper Systems{\slash}Signal).

Compared to messaging, CE carries substantial additional costs for storing teams' documents{\slash}databases and servicing repeated queries for (pieces of) that data.
We speculate that the relatively weak economic incentive for providing privacy-protecting services has not been strong enough to support secure CE applications.
Therefore, a potential direction for \emph{economically viable} secure CE is decentralization.
This strategy puts the storage and computation costs on end users.\footnotemark{}

\footnotetext{Decentralization might solve the problem of funding the operation of CE systems, but it does not address the cost of developing application code.
Once upon a time, users paid for software; could this happen again?}

Decentralized CE has also been the subject of previous research and deployed systems (e.g. Bayou\cite{Terry1995}, PeerPad (\texttt{peerpad.net})).
Previous decentralized CE systems have all made one or more important usability and{\slash}or scalability compromises relative to centralized systems.
Our goal is to eliminate or mitigate as many of these compromises as possible, since most people in most situations are willing to give up little in exchange for improved data security and privacy\cite{Acquisti2013}.

Here is our brief list of features that we believe are essential for a CE system to be a viable replacement for centralized services:

\begin{itemize}
\item Full asynchrony (i.e. users need not be simultaneously online).
\item No dependence on direct peer-to-peer connections.
\item Integration of concurrent edits, including both conflict detection and automatic merging of compatible edits.
\item Multiple simultaneous ``connections'' from a single user.
\item Anywhere, anytime availability (i.e. no dependence on data on a client device).
\item Low latency.
\item Database size scalability.
\item Team size scalability.
\item Efficient team management.
\end{itemize}

Our proposed protocol (called United We Stand (UWS)) starts with an interesting security{\slash}usability compromise.
We assume that all users have a cloud storage location to which they upload their edits, both for their own later retrieval and to broadcast them to their teammates.
Compared to some secure messaging protocols, where ``old'' messages are assumed to be either deleted or stored on a more physically secure device, this architecture is less secure in the sense that encrypted versions of all the team's data are available to anyone on the Internet.

Nevertheless, we believe that this protocol has the potential to improve the security and privacy for the huge number of teams that currently use conventional centralized CE services.
In order to achieve this kind of mainstream success, the protocol must provide usability nearly indistinguishable from centralized services.
We analyze ways in which we believe previous decentralized CE projects have fallen short in this regard and sketch adaptations of existing secure messaging and distributed systems protocols that we believe could provide that level of usability.

\section{Centralized{\slash}Decentralized Hybrid}

In any networked application there are tensions between security{\slash}privacy and servers playing a role in the application.
Even systems (like SPORC and Signal) that use E2EE are more vulnerable to some attacks than decentralized systems.
First, surveillance is easier with central servers than decentralized communication.
Such surveillance can expose teammate identities and communication patterns, if not the content of messages.
Second, central servers are easier to censor.
In recent years there have been several examples of governments and{\slash}or courts blocking secure messaging systems (e.g. WhatsApp in Brazil, Telegram in Russia, Signal in several countries).
Such blocking is feasible because these applications require communication with central servers.
Third, any server designed in to a protocol raises the question of who pays for the operation of that server.

On the other hand, purely decentralized architectures have three critical usability problems compared to conventional CE.
First, users must be online simultaneously to exchange edits\footnotemark{}.
While this is acceptable in some contexts, it is problematic for users with intermittent internet connections and{\slash}or energy-constrained devices.
Second, firewalls that block incoming connections can make decentralized communication impossible.
The STUN{\slash}TURN{\slash}ICE protocols enable peer-to-peer connections through firewalls in some cases, but they do not always work, and in some cases rely on server support (which is exactly what we are trying to avoid).
Third, if a user wants to access their data from a ``new'' device, there may be nowhere to download the data from at any particular time.

\footnotetext{This does not mean that \emph{all} teammates need to be online simultaneously.
Some P2P CE systems pass edits from user to user as particular pairs happen to be online together.}

We reemphasize that while it is possible for users to work around these difficulties, we are aiming for usability nearly indistinguishable from centralized services.

In UWS we compromise on the server issue by assuming that every user has a passive cloud storage location of some kind.
For many users, this will be an account with commodity services like Dropbox, Google Drive or Microsoft OneDrive.
More technically savvy users with stronger privacy concerns can use an account with a lower profile cloud provider or even run their own storage server.
To be clear, we are \emph{not} saying that all UWS data resides with some particular cloud storage provider, but rather that every user is responsible for providing their own cloud storage location.
Users can choose where to store their data completely independently of any other user's choice.

In our protocol design we minimize the API complexity and performance expectations of the storage server in order to maximize the flexibility that users{\slash}system designers have with filling that role.
The interface is essentially simple file upload{\slash}download.
The only slightly exotic required feature is some atomic checking by the server on upload (e.g. the HTTP \texttt{If-Match} header features).

We briefly note that it should be possible to use P2P connections for lower latency when such connections are available.
Other projects have explored P2P-based CE, so the only question is how hard it is to hybridize these kinds of communication systems with UWS.

\section{Passive Cloud Storage}

The default communication mechanism in UWS is broadcasting messages to teammates by uploading them to a cloud storage location.
A user can participate in multiple teams, storing different files under different keys, as appropriate.

\subsection{Misbehaving Storage Servers}

The UWS protocol does not trust storage servers to enforce its basic security and privacy properties.
All files are encrypted (unless they contain only public information) and cryptographically authenticated.
This means it is infeasible for servers to access teams' confidential data or impersonate teammates.

Storage servers can perform denial of service attacks trivially by deleting data, not responding to requests, or (slightly more subtly) corrupting data.
Because of the authentication, users can at least be aware of any corruption that occurs.
If users are concerned about this kind of denial of service attack, they can create backups offline or even run their own storage server.

Timestamps provided by the storage server are used to break ties in the concurrent edit consistency protocol (described below), which means that storage servers can potentially disrupt teams' data consistency.
Because timestamps are only used in cases where edits are not causally ordered (which is a purely client-side protocol), the degree of inaccuracy that storage servers can introduce this way is limited.
% Servers could also report inconsistent timestamps ...

\subsection{Storage Protocol}

An important feature that UWS requires from the storage subsystem is atomic multi-file uploads.
This is a feature that we do not want to require natively from storage servers, so we build it up from more primitive pieces.
All files stored for a particular user (including all teams they belong to) are organized as a single tree.
The root file has a globally known location{\slash}name{\slash}path.
All other files have randomly generated names; there should never be ``external'' links to these files, they should only be reached by following a chain of links starting from the root file.
Clients modify{\slash}add{\slash}delete files in the style of functional data structures by rebuilding branches of the tree from the modifications up to the root and then performing a single atomic update to the root.

Standard HTTP file servers already support these features with two flavors of the \texttt{If-Match} header.
The \texttt{If-None-Match:*} header makes it possible to avoid collisions between client-generated random names{\slash}paths.
The \texttt{ETag} and \texttt{If-Match:<etag>} headers make it possible to update the root atomically.
Mis-implementations of these features (malicious or not) could lead to data corruption that would be tricky to detect; resistance to such an attack is left to future work.

After a root update, some files may not be reachable from the new root; these should be garbage collected.
Users getting disconnected in the middle of an update, or simultaneous updates coming in from concurrent sessions can never corrupt the tree.
At worst, such problems will lead to retrying the update and{\slash}or creating garbage files.
If multiple sessions are competing to make concurrent updates, at least one will succeed, thus avoiding livelock.

\subsection{Timestamps}

Getting accurate timestamps is somewhat tricky.
We assume that servers assign a reasonably accurate wall-clock timestamp to each file.
However, files are not visible to teammates immediately after the upload completes.
After writing a file that contains some edit, a user must rewrite some additional files to complete a new tree, and then finally update the root.
If a client has a slow connection, there may be substantial delays between when a file is written and when a new tree containing that file is visible to teammates.

To address this issue, we define two kinds of timestamps: server timestamps and link timestamps.
Server timestamps are assigned by the server (e.g. \texttt{Last- Modified} in HTTP).
In UWS the only file for which the server timestamp matters is the root.
Because the UWS data protocol is a tree, each file has a single parent.
Each parent-child link contains a client-supplied timestamp.
These link timestamps can be empty{\slash}unknown (for reasons described in the next paragraph).
A file's \emph{effective timestamp} is defined to be the first non-empty link timestamp in the path from it back to the root, or the root's server timestamp, if all such link timestamps are empty.

When a tree is updated, the link timestamps for all newly created files are empty{\slash}unknown.
When a client updates a branch in the tree, it may find links from files in the new branch to older, unmodified parts of the tree.
If such new $\rightarrow$ old links have an empty{\slash}unknown timestamp, during the writing of the new tree, these links are updated to the effective timestamp of the relevant file.

\subsection{Notification of Changes}

Storing data in the cloud makes it available, but how do users know when they should check for new edits from their teammates?
There are two separate questions here.
First, what basic technologies are available to deliver notifications to users?
Second, especially as team sizes grow, is it possible to avoid checking{\slash}listening for updates from all teammates simultaneously?

The simplest answer to the first question is polling, which has obvious performance problems.
The main solution for push notifications from the large cloud storage providers requires registering a domain name that will run server code, listening for incoming connections from the cloud provider.
This is obviously impractical for many of the users we are interested in.
Another solution that is supported by at least some cloud storage providers is long-polling.

Regarding the second question, the current prototype simply listens for updates from all teammates.
We believe that adapting P2P file sharing{\slash}discovery protocols should make it practical to propagate updates around large teams more efficiently.

\subsection{Database Format}

For most of the UWS protocol, the content of the edits is irrelevant.
The only essential feature for building a useful system is that older edits somehow be efficiently queryable.
The current UWS prototype adopts a very flexible design from the Datomic database.
Primitive units of data are 4-tuples: entity, attribute, value, timestamp (similar to RDF triples).
These tuples are stored in multiple indexes, sorted in different ways to enable flexible and efficient querying.
New edits accumulate in a linear chain until some threshold is reached, when a batch is integrated into the indexes.
The indexes are stored as wide{\slash}shallow trees.

\subsection{Sharing the Storage Cost Between Teammates}

As noted above, in basic UWS each teammate stores a complete copy of the team's data.
Because of the functional-style tree storage format, there is a relatively simple approach to sharing that could be implemented.
Because the UWS trees are wide, the vast majority of the data is in the leaves.
When a client updates its indexes by adding a batch of edits, they can announce the identity of the new leaf files they have created.
When teammates update their own storage trees, they can store references to their teammates leaf files instead of storing their own copies.

This sharing idea relies on teammates trusting each other to not delete their part of the team's shared data.
In other words, if a team is sharing the storage cost, it would be easy for a teammate to do a denial of service attack by removing their data.

\section{Ordering Edits Efficiently in the Common Case}

There has been a great deal of research on conflict detection and automatic merging of concurrent edits.
Many recent CE systems have put a lot of focus on automatic merging with some flavor of operational transformations (OT) or conflict-free replicated data types (CRDTs).
These concurrent edit merging frameworks are useful, but do not themselves provide support for identification and resolution of true conflicts.
We prefer to base our protocol's core data model on a Bayou-like totally ordered chain of edits{\slash}transactions.
It is conceptually straightforward to build OT or CRDT like data abstractions on top of such a model.

\subsection{Bayou}

In Bayou, the basic data model is a linear chain of edits (\emph{Writes} in their jargon).
Of course, each user has their own perspective on the exact state of ``the'' chain.
Bayou divides the chain into two sections: tentative and committed.
New edits are initially considered tentative.
A consistency protocol determines when edits graduate from tentative to stable{\slash}committed.

The order of stable edits has been agreed upon, and cannot be changed by subsequent messages.
Tentative edits might be reordered or superseded by as-yet-unseen edits.
Client user interfaces are free to incorporate tentative edits, but later messages might cause unexpected changes in application state.
This flexibility is an important usability advantage of Bayou.
Application programmers can choose on a case-by-case basis whether tentative state should appear in the UI and how users should be notified of changes to such state.

UWS makes two additions to the Bayou work:

\begin{itemize}
\item A tweak on classic causal ordering protocols that is efficient in an important common case and takes advantage of the passive file servers in UWS
\item Blurring the tentative{\slash}committed line
\end{itemize}

\subsection{Efficient Causal Ordering}

It is well known that in the worst case, establishing causal ordering in a distributed system requires time and space linear in the number of participants.
This would seem to put an unacceptable overhead on team size scaling.
However, in many CE application contexts there is an important pattern to exploit: the frequency of actually concurrent editing is not that high.
This can improve the efficiency of establishing a causal order, because clients do not need to send a full vector timestamp with each edit.
Rather, each client keeps a copy of the partial order of edits and sends a set of pointers to what it believes to be the most recent edits.

In the common case of relatively infrequent and non-concurrent edits, the partial order will be a completely linear chain, and the set of most recent edits will be of size one.
As the degree of concurrency increases, the size of the most recent set grows, up to a limit of the team size.

Causal ordering establishes only a partial order among edits.
Concurrent edits are ordered by the server-supplied timestamps.
Because users are potentially uploading to different servers, and some servers may be setting timestamps maliciously, there is room here for edits to end up in the ``wrong'' order.
However, because of the causal ordering protocol, the scope for edit ordering to violate user expectations is small.
In fact, some CE protocols use something arbitrary like user ID ordering to break these kinds of ties.
Using the timestamps is a best-effort addition to help align edit ordering with user expectations.

\subsection{How Tentative is Tentative?}

As mentioned above, Bayou splits each client's edit chain into two sections: tentative and committed.
We believe that it is useful to consider more intermediate degrees of ``committedness''.
Exactly which levels of committedness are useful will require experimentation with real applications, but UWS currently supports the following levels:

\begin{itemize}
\item Not yet uploaded
\item Uploaded, but not confirmed by the server
\item Upload confirmed, but no acknowledgments from teammates seen
\item Acknowledged by a minority of teammates
\item Acknowledged by a majority of teammates (i.e. committed)
\end{itemize}

We believe acknowledged by a minority of teammates is an especially interesting intermediate state in the following scenario.
Consider a relatively large team, where many teammates log in to the team relatively infrequently.
(say, scheduling volunteer docents at a museum.)
Conventional distributed consensus algorithms demand a majority in order to consider some data committed, because of the possibility that two minority subgroups are isolated from each other.
UWS has not defeated the CAP theorem, but we expect this kind of partition to be extremely rare as long as the cloud storage servers are operating normally.
So an application might prefer to display data as committed, even if it has only been acknowledged by a minority of teammates.
(Of course, such an application would need a backup UI{\slash}UX in the extremely unlikely event that such data needs to be ``uncommitted''.)

% Datomic querying below

\section{Efficient Secure Group Messaging}

To a first approximation, any secure group messaging protocol can be used with with the rest of UWS.
Where messaging protocols refer to sending messages to other users or a server to be forwarded, in UWS that would be uploading a new file to the ``outbox'' location in the tree for the relevant team.

The current prototype of UWS uses an adaptation of the Signal group messaging protocol.
We are planning on switching to an adaptation of Asynchronous Ratcheting Trees (ART)\cite{Cohn-Gordon2018} soon.

An interesting modest difference between UWS and most secure messaging protocols is that most protocol designs make an implicit (or explicit) assumption that after messages have been delivered and decrypted, the messages are either stored in some physically more secure location or deleted entirely.
This is an important part of what makes \emph{forward secrecy} an interesting property.
Forward secret protocols protect ``old'' messages by discarding the keys that were used to encrypt them.
But in UWS, copies of all the teams' data are stored for anyone to download.
If an adversary manages to get a user's current master key, they can decrypt a team's entire database.

Mixing new randomness into the keys used to broadcast edits is only important in a couple of cases: when a user leaves a team, or when a team decides to permanently expunge some piece of data from its database.
It is only necessary to do a something like a group key exchange in one of these scenarios, as opposed to with every message exchange, as in protocols like Signal.
For normal message broadcasting, clients perform a simple key derivation chain operation.

UWS can turn this security trade-off (i.e. exposing encrypted copies of the data to the Internet) into a modest performance advantage relative to conventional secure group messaging, because of the less frequent key exchange operations.
In the case of Signal group messaging this is a significant scaling difference, because the ratcheting protocol work and bandwidth scale linearly with team size.
The ART protocol scales sub-linearly, so the difference is less dramatic, but it still exists.

\section{Summary}

We believe that there is no fundamental technical reason that secure collaborative editing cannot achieve the wide mainstream use that secure messaging has.
United We Stand (UWS) is our attempt to address what we see as the challenges to building secure CE that is as usable{\slash}scalable{\slash}efficient (or nearly so) as conventional (\emph{insecure}) centralized approaches.
In particular, we design our protocol around per-user commodity cloud storage accounts.
We presented tweaks to existing secure messaging and{\slash}or decentralized CE protocols that strike a balance between efficiency and simplicity for use patterns that we believe to be common in collaborative editing applications.

\bibliographystyle{splncs04}
\bibliography{./uws.bib}

\end{document}
